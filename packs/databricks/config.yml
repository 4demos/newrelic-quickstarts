
# Name of the pack (required)
name: databricks
title: Databricks Integration
description: >-
  Databricks is an orchestration platform for Apache Spark. This pack enables monitoring of Databricks Spark applications with New Relic Spark integration 
  The integration provides a script you can run in a notebook to generate an installation script to attach to a cluster and populate Spark metrics to New relic Insights events. This helps you easily track the health of your Databricks clusters, fine-tune your Spark jobs for peak performance, and troubleshoot problems.

  Databricks clusterâ€™s driver node runs each job in scheduled stages. Individual stages are broken down into tasks and distributed across executor nodes. New Relic Spark integration collects detailed job and stage metrics so you can get granular insight into job performance at a glance. For example , you can break down the Job metric by status (successful, pending, or failed) to see in real-time if a high number of jobs are failing, which could indicate a code error or memory issue at the executor level. Metric on  the number of jobs ub realtime can also help you make decisions for provisioning clusters in the future.


summary: >-
  Monitor Databricks Spark applications with New Relic Spark integration using notebook script

icon: icon.png
logo: logo.png
# Support level: New Relic | Verified | Community (required)
level: Community

website: https://databricks.com/

keywords:
  - nrlabs
  - nrlabs-data
  - apache spark
  - spark
  - databricks 

# Authors of the pack (required)
authors:
  - New Relic Labs

documentation:
  - name: Databricks init script creator notebook
    description: >-
      Databricks notebook to create init script to be used during initialization of Databricks cluster 
    url: https://github.com/newrelic-experimental/nri-spark#databricks-init-script-creator-notebook





